{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNrigLLSwbNQ"
      },
      "outputs": [],
      "source": [
        "# importing required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "# from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split,KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import ensemble\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten,Bidirectional\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "ybYP2jC3y1vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYA0agkfwbNT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9f22ebe3-64a5-478b-a715-5ee7580a0ef4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       essay_id  essay_set                                              essay  \\\n",
              "0             1          1  \"Dear local newspaper, I think effects compute...   \n",
              "1             2          1  \"Dear @CAPS1 @CAPS2, I believe that using comp...   \n",
              "2             3          1  \"Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...   \n",
              "3             4          1  \"Dear Local Newspaper, @CAPS1 I have found tha...   \n",
              "4             5          1  \"Dear @LOCATION1, I know having computers has ...   \n",
              "...         ...        ...                                                ...   \n",
              "12973     21626          8  \" In most stories mothers and daughters are ei...   \n",
              "12974     21628          8  \" I never understood the meaning laughter is t...   \n",
              "12975     21629          8  \"When you laugh, is @CAPS5 out of habit, or is...   \n",
              "12976     21630          8  \"                               Trippin' on fe...   \n",
              "12977     21633          8  \" Many people believe that laughter can improv...   \n",
              "\n",
              "       domain1_score  \n",
              "0                  8  \n",
              "1                  9  \n",
              "2                  7  \n",
              "3                 10  \n",
              "4                  8  \n",
              "...              ...  \n",
              "12973             35  \n",
              "12974             32  \n",
              "12975             40  \n",
              "12976             40  \n",
              "12977             40  \n",
              "\n",
              "[12978 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93fbd909-4471-4bf0-b94b-052e22f74fed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Dear local newspaper, I think effects compute...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Dear @CAPS1 @CAPS2, I believe that using comp...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Dear Local Newspaper, @CAPS1 I have found tha...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Dear @LOCATION1, I know having computers has ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12973</th>\n",
              "      <td>21626</td>\n",
              "      <td>8</td>\n",
              "      <td>\" In most stories mothers and daughters are ei...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12974</th>\n",
              "      <td>21628</td>\n",
              "      <td>8</td>\n",
              "      <td>\" I never understood the meaning laughter is t...</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12975</th>\n",
              "      <td>21629</td>\n",
              "      <td>8</td>\n",
              "      <td>\"When you laugh, is @CAPS5 out of habit, or is...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12976</th>\n",
              "      <td>21630</td>\n",
              "      <td>8</td>\n",
              "      <td>\"                               Trippin' on fe...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12977</th>\n",
              "      <td>21633</td>\n",
              "      <td>8</td>\n",
              "      <td>\" Many people believe that laughter can improv...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12978 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93fbd909-4471-4bf0-b94b-052e22f74fed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93fbd909-4471-4bf0-b94b-052e22f74fed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93fbd909-4471-4bf0-b94b-052e22f74fed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "importing_dataset = pd.read_csv('https://github.com/dnyanada02/SmartGrading/blob/main/Dataset/training_set_rel3.tsv?raw=true', quoting=csv.QUOTE_NONE, sep='\\t', encoding='ISO-8859-1')\n",
        "# dependent variable\n",
        "scores = importing_dataset['domain1_score']\n",
        "dataset = importing_dataset.loc[:,['essay_id', 'essay_set', 'essay', 'domain1_score']]\n",
        "dataset.dropna()\n",
        "dataset\n",
        "\n",
        "# dataset = pd.read_csv(\"/content/training_set_rel3.tsv\",sep='\\t', encoding='ISO-8859-1',\n",
        "#                             usecols = ['essay_id', 'essay_set', 'essay','domain1_score']).dropna(axis=1)\n",
        "# scores = dataset['domain1_score']\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "YY7elZCBG_3m",
        "outputId": "0f10c02d-a891-4dd0-b048-91d912375580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           essay_id     essay_set  domain1_score\n",
              "count  12978.000000  12978.000000   12978.000000\n",
              "mean   10295.432809      4.179458       6.799276\n",
              "std     6308.588616      2.136749       8.970357\n",
              "min        1.000000      1.000000       0.000000\n",
              "25%     4439.250000      2.000000       2.000000\n",
              "50%    10045.500000      4.000000       3.000000\n",
              "75%    15680.750000      6.000000       8.000000\n",
              "max    21633.000000      8.000000      60.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ffca2af-cecb-46d3-bb3e-2d8d2bff9725\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12978.000000</td>\n",
              "      <td>12978.000000</td>\n",
              "      <td>12978.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10295.432809</td>\n",
              "      <td>4.179458</td>\n",
              "      <td>6.799276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6308.588616</td>\n",
              "      <td>2.136749</td>\n",
              "      <td>8.970357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4439.250000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>10045.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15680.750000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>21633.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ffca2af-cecb-46d3-bb3e-2d8d2bff9725')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ffca2af-cecb-46d3-bb3e-2d8d2bff9725 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ffca2af-cecb-46d3-bb3e-2d8d2bff9725');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvQ4bmy3wbNT"
      },
      "outputs": [],
      "source": [
        "# Generating word tokens after removing characters other than alphabets, converting them to lower case and\n",
        "# removing stopwords from the text'''\n",
        "\n",
        "def word_tokens(essay_text):\n",
        "    essay_text = re.sub(\"[^a-zA-Z]\", \" \", essay_text)\n",
        "    words = essay_text.lower().split()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    return (words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3SCEfWIwbNU"
      },
      "outputs": [],
      "source": [
        "# Generating sentence tokens from the essay and finally the word tokens\n",
        "\n",
        "def sentence_tokens(essay_text):\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    sent_tokens = tokenizer.tokenize(essay_text.strip())\n",
        "    sentences = []\n",
        "    for sent_token in sent_tokens:\n",
        "        if len(sent_token) > 0:\n",
        "            sentences.append(word_tokens(sent_token))\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_qZDesiwbNV"
      },
      "outputs": [],
      "source": [
        "# Generating a vector of features\n",
        "\n",
        "def makeFeatureVec(words, model, num_features):\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    num_words = 0.\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in index2word_set:\n",
        "            num_words += 1\n",
        "            featureVec = np.add(featureVec,model[word])        \n",
        "    featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8F41_VDwbNV"
      },
      "outputs": [],
      "source": [
        "# Generating word vectors to be used in word2vec model\n",
        "\n",
        "def getAvgFeatureVecs(essays, model, num_features):\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay_text in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay_text, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "OCykKfsR1nfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class attention(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        " \n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
        "                               initializer='random_normal', trainable=True)\n",
        "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
        "                               initializer='zeros', trainable=True)        \n",
        "        super(attention, self).build(input_shape)\n",
        " \n",
        "    def call(self,x):\n",
        "        # Alignment scores. Pass them through tanh function\n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        # Remove dimension of size 1\n",
        "        e = K.squeeze(e, axis=-1)   \n",
        "        # Compute the weights\n",
        "        alpha = K.softmax(e)\n",
        "        # Reshape to tensorFlow format\n",
        "        alpha = K.expand_dims(alpha, axis=-1)\n",
        "        # Compute the context vector\n",
        "        context = x * alpha\n",
        "        context = K.sum(context, axis=1)\n",
        "        return context"
      ],
      "metadata": {
        "id": "iUGjqTbI1o_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_with_attention(hidden_units, dense_units, input_shape, activation):\n",
        "    x=Input(shape=[1, 300])\n",
        "    LSTM_layer = LSTM(300, dropout=0.2, recurrent_dropout=0.2, input_shape=[1, 300], return_sequences=True)(x)\n",
        "    LSTM_layer = Bidirectional(LSTM(64, return_sequences=True))(LSTM_layer)\n",
        "    attention_layer = attention()(LSTM_layer)\n",
        "    # LSTM_layer = LSTM(300, dropout=0.2, recurrent_dropout=0.2, input_shape=[1, 300], return_sequences=True)(attention_layer)\n",
        "    # attention_layer2 = attention()(attention_layer)\n",
        "    # outputs=Dense(dense_units, trainable=True, activation=activation)(attention_layer)\n",
        "    outputs=Dense(1, trainable=True, activation=activation)(attention_layer)\n",
        "    model=Model(x,outputs)\n",
        "    model.compile(loss='mse', optimizer='adam',metrics=['mae'])    \n",
        "    return model"
      ],
      "metadata": {
        "id": "1-DYeUrg1q5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 2"
      ],
      "metadata": {
        "id": "Xn37We-s1vlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7rZdnDK8lqv",
        "outputId": "baab8474-c679-4a7a-c32b-6256a40a79ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kGYVbFCwbNW",
        "outputId": "3b208b3d-99f6-44bb-efd6-51549799908a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------Fold 1------------\n",
            "\n",
            "Training Word2Vec Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1, 300)]          0         \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 1, 300)            721200    \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 1, 128)           186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " attention_5 (attention)     (None, 128)               129       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 908,338\n",
            "Trainable params: 908,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 6s 10ms/step - loss: 63.1385 - mae: 4.4811\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 32.9620 - mae: 3.4522\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 27.6243 - mae: 3.3512\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 25.5691 - mae: 3.2799\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 23.6397 - mae: 3.1434\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 21.2977 - mae: 2.9973\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 19.5448 - mae: 2.8360\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 17.5349 - mae: 2.6899\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 3s 16ms/step - loss: 14.3891 - mae: 2.4643\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 12.3552 - mae: 2.2503\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 11.0203 - mae: 2.0860\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 9.9004 - mae: 1.9027\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 9.1171 - mae: 1.7687\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 8.4580 - mae: 1.6879\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 8.3228 - mae: 1.6509\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 8.0840 - mae: 1.6242\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.6094 - mae: 1.5765\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.3072 - mae: 1.5353\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.0676 - mae: 1.5109\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.8854 - mae: 1.4943\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.8262 - mae: 1.4764\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.4417 - mae: 1.4442\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.7455 - mae: 1.4452\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.5965 - mae: 1.4202\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.1227 - mae: 1.3985\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.1424 - mae: 1.3823\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.2710 - mae: 1.3861\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.1411 - mae: 1.3651\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.0972 - mae: 1.3499\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.4410 - mae: 1.3692\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.9276 - mae: 1.3364\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.8944 - mae: 1.3299\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.8934 - mae: 1.3234\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.7967 - mae: 1.3039\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.6078 - mae: 1.2949\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.6064 - mae: 1.3009\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.5464 - mae: 1.2882\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.6457 - mae: 1.2962\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.6111 - mae: 1.2931\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4593 - mae: 1.2741\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4033 - mae: 1.2673\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.5650 - mae: 1.2738\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4987 - mae: 1.2717\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4586 - mae: 1.2659\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.2447 - mae: 1.2432\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.0936 - mae: 1.2404\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.3542 - mae: 1.2481\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.2022 - mae: 1.2412\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.1390 - mae: 1.2395\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.0950 - mae: 1.2353\n",
            "Mean squared error: 5.79\n",
            "Variance: 0.92\n",
            "Kappa Score: 0.96\n",
            "\n",
            "------------Fold 2------------\n",
            "\n",
            "Training Word2Vec Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1, 300)]          0         \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 1, 300)            721200    \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 1, 128)           186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " attention_6 (attention)     (None, 128)               129       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 908,338\n",
            "Trainable params: 908,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 7s 11ms/step - loss: 63.5339 - mae: 4.5171\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 32.1917 - mae: 3.3988\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 26.4019 - mae: 3.3158\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 24.4240 - mae: 3.2338\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 22.3591 - mae: 3.0651\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 20.3457 - mae: 2.9257\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 17.8627 - mae: 2.7527\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 15.5528 - mae: 2.5758\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 13.4209 - mae: 2.3784\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 12.0893 - mae: 2.2281\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 11.3776 - mae: 2.1353\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 10.3219 - mae: 2.0239\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 9.2773 - mae: 1.8780\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 8.8347 - mae: 1.7856\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 8.1664 - mae: 1.6622\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.6421 - mae: 1.5658\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.8908 - mae: 1.4948\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.1138 - mae: 1.5055\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.8088 - mae: 1.4616\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.6243 - mae: 1.4416\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.6247 - mae: 1.4273\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.4459 - mae: 1.4256\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.1977 - mae: 1.3984\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.3535 - mae: 1.3972\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.3463 - mae: 1.3889\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.2296 - mae: 1.3674\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.8048 - mae: 1.3420\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.8792 - mae: 1.3456\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.8851 - mae: 1.3411\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.8141 - mae: 1.3273\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.7328 - mae: 1.3127\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.6863 - mae: 1.3111\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4697 - mae: 1.2937\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.3481 - mae: 1.2863\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4934 - mae: 1.2977\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.6392 - mae: 1.2902\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.4300 - mae: 1.2782\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.4185 - mae: 1.2799\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.4525 - mae: 1.2791\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.2919 - mae: 1.2681\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.3794 - mae: 1.2693\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.3384 - mae: 1.2595\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4726 - mae: 1.2663\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.2146 - mae: 1.2563\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.2501 - mae: 1.2515\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.1073 - mae: 1.2384\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.1838 - mae: 1.2432\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.1392 - mae: 1.2432\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.1459 - mae: 1.2299\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 4.9839 - mae: 1.2253\n",
            "Mean squared error: 4.85\n",
            "Variance: 0.94\n",
            "Kappa Score: 0.97\n",
            "\n",
            "------------Fold 3------------\n",
            "\n",
            "Training Word2Vec Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1, 300)]          0         \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 1, 300)            721200    \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 1, 128)           186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " attention_7 (attention)     (None, 128)               129       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 908,338\n",
            "Trainable params: 908,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 7s 16ms/step - loss: 62.2195 - mae: 4.4207\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 31.3432 - mae: 3.3605\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 25.8660 - mae: 3.3303\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 23.4018 - mae: 3.1980\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 21.7818 - mae: 3.0569\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 19.2282 - mae: 2.8548\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 15.9031 - mae: 2.5855\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 13.1777 - mae: 2.3019\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 11.2427 - mae: 1.9893\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 9.5857 - mae: 1.7813\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 8.9030 - mae: 1.7049\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 8.4285 - mae: 1.6303\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.9548 - mae: 1.5773\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.5709 - mae: 1.5500\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.4860 - mae: 1.5166\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.0165 - mae: 1.4816\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.9345 - mae: 1.4758\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.8221 - mae: 1.4504\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.5582 - mae: 1.4340\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.5548 - mae: 1.4216\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.4537 - mae: 1.4080\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.4116 - mae: 1.4078\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.4047 - mae: 1.4028\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.2533 - mae: 1.3731\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.8661 - mae: 1.3553\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.9612 - mae: 1.3362\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.0100 - mae: 1.3478\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.8838 - mae: 1.3274\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.0468 - mae: 1.3420\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.8609 - mae: 1.3146\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.6862 - mae: 1.3089\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.5945 - mae: 1.2992\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.6891 - mae: 1.3008\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.8204 - mae: 1.3132\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.6587 - mae: 1.2941\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.3847 - mae: 1.2730\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4311 - mae: 1.2846\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4625 - mae: 1.2756\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.2496 - mae: 1.2576\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.4078 - mae: 1.2644\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.3376 - mae: 1.2584\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.1178 - mae: 1.2460\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.1513 - mae: 1.2473\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.0604 - mae: 1.2375\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.1140 - mae: 1.2507\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.0313 - mae: 1.2335\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.0941 - mae: 1.2413\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.1141 - mae: 1.2356\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.1233 - mae: 1.2374\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 4.9909 - mae: 1.2282\n",
            "Mean squared error: 5.23\n",
            "Variance: 0.93\n",
            "Kappa Score: 0.97\n",
            "\n",
            "------------Fold 4------------\n",
            "\n",
            "Training Word2Vec Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 1, 300)]          0         \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 1, 300)            721200    \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirectio  (None, 1, 128)           186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " attention_8 (attention)     (None, 128)               129       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 908,338\n",
            "Trainable params: 908,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 6s 10ms/step - loss: 62.2895 - mae: 4.4525\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 32.1291 - mae: 3.3798\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 26.4440 - mae: 3.3239\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 24.5268 - mae: 3.2035\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 22.5011 - mae: 3.0922\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 20.9679 - mae: 2.9539\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 18.8263 - mae: 2.7503\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 15.7762 - mae: 2.5275\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 12.2594 - mae: 2.1806\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 10.8394 - mae: 1.9659\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 9.4674 - mae: 1.8224\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 9.1248 - mae: 1.7378\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 8.1539 - mae: 1.6548\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.8407 - mae: 1.6049\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.2751 - mae: 1.5465\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.3094 - mae: 1.5224\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.7658 - mae: 1.4883\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.7923 - mae: 1.4670\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 6.5537 - mae: 1.4403\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.5259 - mae: 1.4286\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.3659 - mae: 1.4047\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.2473 - mae: 1.3990\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.2709 - mae: 1.3910\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.0680 - mae: 1.3732\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.9083 - mae: 1.3589\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.8807 - mae: 1.3370\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.6644 - mae: 1.3315\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.6724 - mae: 1.3212\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.5467 - mae: 1.3121\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.5036 - mae: 1.3002\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.5152 - mae: 1.2991\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.6556 - mae: 1.2942\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.4857 - mae: 1.2864\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.4942 - mae: 1.2816\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.4509 - mae: 1.2766\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.3191 - mae: 1.2641\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.2839 - mae: 1.2688\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.2116 - mae: 1.2568\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.0922 - mae: 1.2522\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 4.9528 - mae: 1.2288\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.3778 - mae: 1.2550\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.1527 - mae: 1.2409\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.0622 - mae: 1.2301\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.0303 - mae: 1.2251\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.2216 - mae: 1.2346\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 4.8707 - mae: 1.2151\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 4.9780 - mae: 1.2164\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 4.9375 - mae: 1.2079\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 4.7888 - mae: 1.2038\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 4.7047 - mae: 1.1907\n",
            "Mean squared error: 7.06\n",
            "Variance: 0.92\n",
            "Kappa Score: 0.96\n",
            "\n",
            "------------Fold 5------------\n",
            "\n",
            "Training Word2Vec Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 1, 300)]          0         \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 1, 300)            721200    \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, 1, 128)           186880    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " attention_9 (attention)     (None, 128)               129       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 908,338\n",
            "Trainable params: 908,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "163/163 [==============================] - 7s 10ms/step - loss: 61.8962 - mae: 4.4461\n",
            "Epoch 2/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 32.7903 - mae: 3.4171\n",
            "Epoch 3/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 27.5809 - mae: 3.3400\n",
            "Epoch 4/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 25.4498 - mae: 3.2581\n",
            "Epoch 5/50\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 23.3125 - mae: 3.1116\n",
            "Epoch 6/50\n",
            "163/163 [==============================] - 2s 15ms/step - loss: 22.0430 - mae: 3.0205\n",
            "Epoch 7/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 19.5145 - mae: 2.8549\n",
            "Epoch 8/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 16.9173 - mae: 2.6401\n",
            "Epoch 9/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 13.9933 - mae: 2.3340\n",
            "Epoch 10/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 11.4182 - mae: 2.0381\n",
            "Epoch 11/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 10.0754 - mae: 1.8951\n",
            "Epoch 12/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 9.2164 - mae: 1.7794\n",
            "Epoch 13/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 8.5957 - mae: 1.7008\n",
            "Epoch 14/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 8.3340 - mae: 1.6531\n",
            "Epoch 15/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.7520 - mae: 1.6061\n",
            "Epoch 16/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.5331 - mae: 1.5615\n",
            "Epoch 17/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.9835 - mae: 1.5173\n",
            "Epoch 18/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.0654 - mae: 1.5012\n",
            "Epoch 19/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 7.0260 - mae: 1.4788\n",
            "Epoch 20/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.9626 - mae: 1.4751\n",
            "Epoch 21/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.6093 - mae: 1.4314\n",
            "Epoch 22/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.5582 - mae: 1.4229\n",
            "Epoch 23/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.1964 - mae: 1.3929\n",
            "Epoch 24/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.4296 - mae: 1.3915\n",
            "Epoch 25/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.2949 - mae: 1.3885\n",
            "Epoch 26/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.2351 - mae: 1.3810\n",
            "Epoch 27/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 6.2185 - mae: 1.3682\n",
            "Epoch 28/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.9581 - mae: 1.3499\n",
            "Epoch 29/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.9356 - mae: 1.3445\n",
            "Epoch 30/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.8342 - mae: 1.3302\n",
            "Epoch 31/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.6877 - mae: 1.3214\n",
            "Epoch 32/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.7907 - mae: 1.3244\n",
            "Epoch 33/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.6465 - mae: 1.3134\n",
            "Epoch 34/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.5572 - mae: 1.2988\n",
            "Epoch 35/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.8640 - mae: 1.3143\n",
            "Epoch 36/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.5822 - mae: 1.2972\n",
            "Epoch 37/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.5401 - mae: 1.2908\n",
            "Epoch 38/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.3665 - mae: 1.2847\n",
            "Epoch 39/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.3048 - mae: 1.2756\n",
            "Epoch 40/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.6427 - mae: 1.2934\n",
            "Epoch 41/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.3101 - mae: 1.2646\n",
            "Epoch 42/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.2608 - mae: 1.2620\n",
            "Epoch 43/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.2173 - mae: 1.2576\n",
            "Epoch 44/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 5.2361 - mae: 1.2590\n",
            "Epoch 45/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.2690 - mae: 1.2598\n",
            "Epoch 46/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.3298 - mae: 1.2601\n",
            "Epoch 47/50\n",
            "163/163 [==============================] - 2s 11ms/step - loss: 4.9613 - mae: 1.2378\n",
            "Epoch 48/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.0867 - mae: 1.2404\n",
            "Epoch 49/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.0871 - mae: 1.2384\n",
            "Epoch 50/50\n",
            "163/163 [==============================] - 2s 10ms/step - loss: 5.0275 - mae: 1.2338\n",
            "Mean squared error: 6.36\n",
            "Variance: 0.93\n",
            "Kappa Score: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Applying k-fold cross validation\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "cv.get_n_splits(len(dataset))\n",
        "results = []\n",
        "y_pred_list = []\n",
        "\n",
        "count = 1\n",
        "for traincv, testcv in cv.split(dataset):\n",
        "    print(\"\\n------------Fold {}------------\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = dataset.iloc[testcv], dataset.iloc[traincv], scores.iloc[testcv], scores.iloc[traincv]\n",
        "    \n",
        "    train_essays = X_train['essay']\n",
        "    test_essays = X_test['essay']\n",
        "    \n",
        "    sentences = []\n",
        "    \n",
        "    for essay in train_essays:\n",
        "            # Obtaining all sentences from the training set of essays.\n",
        "            sentences += sentence_tokens(essay)\n",
        "            \n",
        "    # Initializing variables for word2vec model.\n",
        "    num_features = 300 \n",
        "    min_word_count = 40\n",
        "    num_workers = 4\n",
        "    context = 10\n",
        "    downsampling = 1e-3\n",
        "\n",
        "    print(\"Training Word2Vec Model...\")\n",
        "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "\n",
        "    model.init_sims(replace=True)\n",
        "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
        "\n",
        "    clean_train_essays = []\n",
        "    \n",
        "    # Generate training and testing data word vectors.\n",
        "    for essay_text in train_essays:\n",
        "        clean_train_essays.append(word_tokens(essay_text))\n",
        "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
        "    \n",
        "    clean_test_essays = []\n",
        "    for essay_text in test_essays:\n",
        "        clean_test_essays.append(word_tokens(essay_text))\n",
        "    testDataVecs = getAvgFeatureVecs(clean_test_essays, model, num_features)\n",
        "    \n",
        "    trainDataVecs = np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
        "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    trainDataVecs = np.nan_to_num(trainDataVecs.astype(np.float32))\n",
        "    testDataVecs = np.nan_to_num(testDataVecs.astype(np.float32))\n",
        "\n",
        "    # lstm_model = get_model()\n",
        "    # lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
        "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
        "\n",
        "\n",
        "    lstm_model= create_with_attention(hidden_units=hidden_units, dense_units=64, input_shape=(300,1), activation='relu')\n",
        "    lstm_model.summary() \n",
        "    history = lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
        "    lstm_model.save(\"Attention_LSTM.h5\")\n",
        "    y_pred = lstm_model.predict(testDataVecs)\n",
        "    \n",
        "    # Round y_pred to the nearest integer.\n",
        "    y_pred = np.around(y_pred)\n",
        "    \n",
        "    '''Evaluation metric used : \n",
        "    1. Mean squared error\n",
        "    2. Variance\n",
        "    3. Cohen's kappa score\n",
        "    Expected results - Minimum error, maximum variance(For variance, best possible score is 1.0, lower \n",
        "    values are worse.) and maximum kappa score(1 depicting the best scores)'''\n",
        "    \n",
        "    # Mean squared error\n",
        "    print(\"Mean squared error: {0:.2f}\".format(mean_squared_error(y_test.values, y_pred)))\n",
        "\n",
        "    # Explained variance score: 1 is perfect prediction\n",
        "    print('Variance: {0:.2f}'.format(explained_variance_score(y_test.values, y_pred)))  \n",
        "    \n",
        "    #Cohen's kappa score\n",
        "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
        "    print(\"Kappa Score: {0:.2f}\".format(result))\n",
        "    results.append(result)\n",
        "\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY0sZNHCwbNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03afbac-68b3-4e29-8bf5-096da652f707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Kappa score after a 5-fold cross validation:  0.96\n"
          ]
        }
      ],
      "source": [
        "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "F51JYMUFJeKM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v9Zp6wHwbNa"
      },
      "outputs": [],
      "source": [
        "# As lstm outperforms all other models, so using it for predicting the scores for the final dataset\n",
        "valid_set = pd.read_csv('https://github.com/dnyanada02/SmartGrading/blob/main/Dataset/valid_set.tsv?raw=true', sep='\\t', encoding='ISO-8859-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbWH-f0jwbNb"
      },
      "outputs": [],
      "source": [
        "valid_set = valid_set.drop(['domain2_predictionid'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiHV6q1DwbNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a20be24-8dc0-476c-aad2-b4a8c32a629a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
              "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
              "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
              "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
              "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
              "\n",
              "   domain1_predictionid  \n",
              "0                  1788  \n",
              "1                  1789  \n",
              "2                  1790  \n",
              "3                  1791  \n",
              "4                  1792  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11f635d5-92ab-4c9d-a22d-78c09954b931\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_predictionid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1788</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
              "      <td>1788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1789</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
              "      <td>1789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1790</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
              "      <td>1790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1791</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
              "      <td>1791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1792</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
              "      <td>1792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11f635d5-92ab-4c9d-a22d-78c09954b931')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11f635d5-92ab-4c9d-a22d-78c09954b931 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11f635d5-92ab-4c9d-a22d-78c09954b931');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "valid_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1S-EJOOwbNb"
      },
      "outputs": [],
      "source": [
        "valid_test_essays = valid_set['essay']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tQuvATawbNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba90b10-d7af-433e-9268-7688103f5e2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Dear @ORGANIZATION1, @CAPS1 more and more peop...\n",
              "1       Dear @LOCATION1 Time @CAPS1 me tell you what I...\n",
              "2       Dear Local newspaper, Have you been spending a...\n",
              "3       Dear Readers, @CAPS1 you imagine how life woul...\n",
              "4       Dear newspaper, I strongly believe that comput...\n",
              "                              ...                        \n",
              "4213     Have you ever noticed that if two little kids...\n",
              "4214                                Laughter @CAPS1 I ...\n",
              "4215     Laughter in @CAPS1 A laugh is not just an act...\n",
              "4216      LAUGHTER @CAPS1 i was younger my friend live...\n",
              "4217     You know how the saying goes live, laugh, lov...\n",
              "Name: essay, Length: 4218, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "valid_test_essays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK39hbJdwbNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77b2e65-bfa7-4dd5-9b1b-3496e3a70106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Word2Vec Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "    \n",
        "for valid_essay in valid_test_essays:\n",
        "        sentences += sentence_tokens(valid_essay)\n",
        "            \n",
        "num_features = 300 \n",
        "min_word_count = 40\n",
        "num_workers = 4\n",
        "context = 10\n",
        "downsampling = 1e-3\n",
        "\n",
        "print(\"Training Word2Vec Model...\")\n",
        "model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "\n",
        "model.init_sims(replace=True)\n",
        "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
        "\n",
        "valid_clean_test_essays = []\n",
        "    \n",
        "# Generate training and testing data word vectors.\n",
        "for essay_text in valid_test_essays:\n",
        "    valid_clean_test_essays.append(word_tokens(essay_text))\n",
        "valid_testDataVecs = getAvgFeatureVecs(valid_clean_test_essays, model, num_features)\n",
        "\n",
        "valid_testDataVecs = np.array(valid_testDataVecs)\n",
        "# Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
        "valid_testDataVecs = np.reshape(valid_testDataVecs, (valid_testDataVecs.shape[0], 1, valid_testDataVecs.shape[1]))\n",
        "    \n",
        "predicted_scores = lstm_model.predict(valid_testDataVecs)\n",
        "    \n",
        "# Round y_pred to the nearest integer.\n",
        "predicted_scores = np.around(predicted_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuB3tiz2wbNc"
      },
      "outputs": [],
      "source": [
        "submission = valid_set.drop(['essay'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlXnfkPYwbNd"
      },
      "outputs": [],
      "source": [
        "predicted_score = predicted_scores.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p--cD_h3wbNd"
      },
      "outputs": [],
      "source": [
        "predicted_score = pd.Series([score for sublist in predicted_scores for score in sublist])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjipxpslwbNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5b00a6-95a9-4bdb-88ee-8e83d59b65b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        9.0\n",
              "1        6.0\n",
              "2       11.0\n",
              "3       12.0\n",
              "4        9.0\n",
              "        ... \n",
              "4213    34.0\n",
              "4214    17.0\n",
              "4215    26.0\n",
              "4216    10.0\n",
              "4217    20.0\n",
              "Length: 4218, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "predicted_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtO50dzCwbNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44245339-76ef-477d-e9b1-4b6c8352041a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "submission = pd.concat([submission, predicted_score], axis = 1).rename(columns = {0:\"predicted_score\"}).iloc[:,[2,0,1,3]]\n",
        "submission.to_excel(\"Submission.xls\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qan3MwXWwbNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ba52b1-3540-4c6f-aab8-87a7062b70fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.07      0.11        81\n",
            "         1.0       0.54      0.41      0.46       348\n",
            "         2.0       0.41      0.56      0.47       469\n",
            "         3.0       0.49      0.61      0.54       588\n",
            "         4.0       0.59      0.23      0.33       311\n",
            "         5.0       0.09      0.05      0.06        20\n",
            "         6.0       0.14      0.04      0.06        26\n",
            "         7.0       0.10      0.14      0.12        22\n",
            "         8.0       0.44      0.40      0.42       130\n",
            "         9.0       0.20      0.47      0.28        73\n",
            "        10.0       0.38      0.15      0.21        82\n",
            "        11.0       0.08      0.03      0.04        33\n",
            "        12.0       0.33      0.12      0.18        24\n",
            "        13.0       0.19      0.19      0.19        16\n",
            "        14.0       0.18      0.12      0.15        16\n",
            "        15.0       0.10      0.20      0.14        15\n",
            "        16.0       0.16      0.13      0.14        39\n",
            "        17.0       0.17      0.21      0.19        34\n",
            "        18.0       0.08      0.16      0.11        19\n",
            "        19.0       0.11      0.21      0.15        19\n",
            "        20.0       0.14      0.12      0.13        17\n",
            "        21.0       0.13      0.15      0.14        13\n",
            "        22.0       0.20      0.19      0.19        16\n",
            "        23.0       0.14      0.07      0.09        15\n",
            "        24.0       0.00      0.00      0.00        21\n",
            "        25.0       0.00      0.00      0.00         0\n",
            "        26.0       0.00      0.00      0.00         0\n",
            "        27.0       0.00      0.00      0.00         1\n",
            "        28.0       0.00      0.00      0.00         3\n",
            "        29.0       0.00      0.00      0.00         2\n",
            "        30.0       0.00      0.00      0.00         7\n",
            "        31.0       0.00      0.00      0.00         6\n",
            "        32.0       0.00      0.00      0.00         6\n",
            "        33.0       0.12      0.14      0.13         7\n",
            "        34.0       0.00      0.00      0.00         7\n",
            "        35.0       0.09      0.08      0.08        13\n",
            "        36.0       0.12      0.17      0.14        12\n",
            "        37.0       0.15      0.50      0.23         8\n",
            "        38.0       0.00      0.00      0.00         2\n",
            "        39.0       0.00      0.00      0.00         1\n",
            "        40.0       0.14      0.07      0.09        29\n",
            "        41.0       0.33      0.17      0.22         6\n",
            "        42.0       0.00      0.00      0.00         7\n",
            "        43.0       0.00      0.00      0.00         4\n",
            "        44.0       0.00      0.00      0.00         5\n",
            "        45.0       0.00      0.00      0.00         9\n",
            "        46.0       0.00      0.00      0.00         3\n",
            "        47.0       0.00      0.00      0.00         2\n",
            "        48.0       0.00      0.00      0.00         2\n",
            "        49.0       0.00      0.00      0.00         1\n",
            "        50.0       0.00      0.00      0.00         4\n",
            "        55.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.38      2595\n",
            "   macro avg       0.13      0.12      0.11      2595\n",
            "weighted avg       0.40      0.38      0.37      2595\n",
            "\n",
            "Confusion matix:\n",
            " [[  6  51  19 ...   0   0   0]\n",
            " [ 12 142 170 ...   0   0   0]\n",
            " [  7  59 262 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]]\n",
            "Cohen-kappa score: 0.9621216139427621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,cohen_kappa_score\n",
        "\n",
        "# print('training accuracy:',trainDataVecs[1]*100)\n",
        "# print('testing accuracy:',testDataVecs[1]*100)\n",
        "\n",
        "# y_pred = lstm_model.predict(testDataVecs)\n",
        "# y_pred = np.around(y_pred)\n",
        "print(classification_report(y_test.values,y_pred))\n",
        "print('Confusion matix:\\n',confusion_matrix(y_test.values,y_pred))\n",
        "print('Cohen-kappa score:',cohen_kappa_score(y_test.values,y_pred,weights='quadratic'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "EssayGrading_Attention_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}